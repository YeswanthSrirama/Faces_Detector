{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702904ac",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9fc738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition  #Please go through Readme for installation guide\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf2902",
   "metadata": {},
   "source": [
    "## Loading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2909df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'source/image/'  #give the path of images to be detected\n",
    "# NOTE: Make sure the images have valid names\n",
    "images_path = [path+i for i in os.listdir(path)]  #Stores the location of each image\n",
    "images_name = [i.split('.')[0] for i in os.listdir(path)]  #Stores the name of images\n",
    "print(images_path,images_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942636d3",
   "metadata": {},
   "source": [
    "## Encoding the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "824f7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_rgb = []\n",
    "images_encoded = []\n",
    "for i in images_path:\n",
    "    img = cv2.imread(i) #reading each image\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  #converting the images from BGR to RGB\n",
    "    images_rgb.append(img)  #storing the image\n",
    "    img_enc = face_recognition.face_encodings(img)[0]  #find the face in the image and encode. Given [0] since it returns a list\n",
    "#     NOTE: Make sure the image has only one face\n",
    "    images_encoded.append(img_enc) #Store the image in a list\n",
    "\n",
    "\n",
    "if images_encoded:\n",
    "    print('{} images found'.format(len(images_encoded)))  #Make sure if the images are encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8beb77",
   "metadata": {},
   "source": [
    "## Reading video, detecting the faces, writing new video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1382da45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_path = './source/Snapchat-1037989622.mp4'  #Give the source path to video\n",
    "cap = cv2.VideoCapture(source_path)  #Capturing the video in a object\n",
    "frame_width = int(cap.get(3)) # .get(3) gives width of the video\n",
    "frame_height = int(cap.get(4))  # .get(4) gives height of the video\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "cap2 = cv2.VideoWriter('cap2.mp4', cv2.VideoWriter_fourcc(*'XVID'), fps, (frame_width, frame_height)) # append frame by frame with source video reference\n",
    "#               ('New Video Name', compressor type,                 frames per second. can be any int,  ) \n",
    "\n",
    "names = images_name[::-1]  #Reversing the names list\n",
    "\n",
    "print(cap.isOpened()) #Check if the source video is open\n",
    "a=0\n",
    "while True:\n",
    "    ret, frame = cap.read() # Reading the i'th frame of video for the i'th loop. ret will have either(True/False), frame contains the frame\n",
    "    a+=1\n",
    "    if not ret:  #Break the loop if no frames exists in the video\n",
    "        break\n",
    "    face_locations = face_recognition.face_locations(frame) # gives you all the locations of faces detected on frame\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations) # Encode the detected faces alone\n",
    "    \n",
    "    #time to compare\n",
    "    face_names = []\n",
    "    name = 'Unknown'  #This is to pass when the faces are found but not matched\n",
    "    for face_encoded in face_encodings:\n",
    "        matches = face_recognition.compare_faces(images_encoded, face_encoded) #gives true or false to each image\n",
    "#         print('matches',matches)\n",
    "        face_distances = face_recognition.face_distance(images_encoded, face_encoded)  #gives confidence of matching\n",
    "#         print('face_distances',face_distances)\n",
    "        best_match_index = np.argmin(face_distances) #gives position of the image with minimum confidence\n",
    "#         print(best_match_index)\n",
    "        if matches[best_match_index]:\n",
    "            name = images_name[best_match_index]  #stores the name of the image if there is a match\n",
    "            print('found: {} at frame {}'.format(name, a))\n",
    "        face_names.append(name)  #stores all the names detected in the video\n",
    "    \n",
    "#     Draw rectangle and name on face\n",
    "    for face_loc in face_locations:\n",
    "        y1, x2, y2, x1 = face_loc[0],face_loc[1],face_loc[2],face_loc[3] #take the position of faces\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2),(255,0,0), 2)  #draws a rectangle around the face\n",
    "#                    (frame, (left top corner), (bottom right corner), rectangle color, thickness)\n",
    "        cv2.putText(frame, name, (x1,y1-10), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 200), 2)  #Writes name above the rectangle\n",
    "#                  (frame, name of the person in the image, (position of text), font style, (color, thickness))\n",
    "    \n",
    "\n",
    "    cap2.write(frame)  #adds the frame to the video along with drawn rect and text\n",
    "    \n",
    "cap.release()  #make sure to release the video or else you cannot open the video\n",
    "cap2.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9368d301",
   "metadata": {},
   "source": [
    "# Detect faces with camera\n",
    "\n",
    "### Only few minor changes are to be done on defining the source. Rest all will be same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e41870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['source/image/surya.jpg', 'source/image/Vinutha.jpg', 'source/image/yashu.jpg']\n",
      "3 images found\n",
      "True\n",
      "name yashu\n",
      "name yashu\n",
      "name yashu\n",
      "name yashu\n",
      "name yashu\n",
      "name yashu\n",
      "name yashu\n",
      "name yashu\n",
      "name surya\n",
      "name surya\n",
      "name surya\n",
      "name surya\n",
      "name yashu\n",
      "name surya\n",
      "name yashu\n",
      "name yashu\n",
      "name yashu\n",
      "name yashu\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path = 'source/image/'  #give the path of images to be detected\n",
    "# NOTE: Make sure the images have valid names\n",
    "images_path = [path+i for i in os.listdir(path)]  #Stores the location of each image\n",
    "images_name = [i.split('.')[0] for i in os.listdir(path)]  #Stores the name of images\n",
    "print(images_path)\n",
    "\n",
    "images_rgb = []\n",
    "images_encoded = []\n",
    "for i in images_path:\n",
    "    img = cv2.imread(i) #reading each image\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  #converting the images from BGR to RGB\n",
    "    images_rgb.append(img)  #storing the images\n",
    "    img_enc = face_recognition.face_encodings(img)[0]  #find the face in the image and encode. Given [0] since it returns a list\n",
    "#     NOTE: Make sure the image has only one face\n",
    "    images_encoded.append(img_enc) #Store the image in a list\n",
    "\n",
    "\n",
    "if images_encoded:\n",
    "    print('{} images found'.format(len(images_encoded)))  #Make sure if the images are encoded\n",
    "    \n",
    "source = 0  #Give the camera index. 0 will work if there is only one cam\n",
    "cap = cv2.VideoCapture(source)  #Capturing the video in a object\n",
    "frame_width = int(cap.get(3)) # .get(3) gives width of the video\n",
    "frame_height = int(cap.get(4))  # .get(4) gives height of the video\n",
    "\n",
    "names = images_name[::-1]  #Reversing the names list\n",
    "print(cap.isOpened()) #Check if the source video is open\n",
    "while True:\n",
    "    ret, frame = cap.read() # Reading the i'th frame of video for the i'th loop. ret will have either(True/False), frame contains the frame\n",
    "    if not ret:  #Break the loop if no frames exists in the video\n",
    "        break\n",
    "    face_locations = face_recognition.face_locations(frame) # gives you all the locations of faces detected on frame\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations) # Encode the detected faces alone\n",
    "    \n",
    "    #time to compare\n",
    "    face_names = []\n",
    "    name = 'Unknown'  #This is to pass when the faces are found but not matched\n",
    "    for face_encoded in face_encodings:\n",
    "        matches = face_recognition.compare_faces(images_encoded, face_encoded) #gives true or false to each image\n",
    "#         print('matches',matches)\n",
    "        face_distances = face_recognition.face_distance(images_encoded, face_encoded)  #gives confidence of matching\n",
    "#         print('face_distances',face_distances)\n",
    "        best_match_index = np.argmin(face_distances) #gives position of the image with minimum confidence\n",
    "#         print(best_match_index)\n",
    "        if matches[best_match_index]:\n",
    "            name = images_name[best_match_index]  #stores the name of the image if there is a match\n",
    "            print('name',name)\n",
    "        face_names.append(name)  #stores all the names detected in the video\n",
    "    \n",
    "#     Draw rectangle and name on face\n",
    "    for face_loc in face_locations:\n",
    "        y1, x2, y2, x1 = face_loc[0],face_loc[1],face_loc[2],face_loc[3] #take the position of faces\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2),(255,0,0), 2)  #draws a rectangle around the face\n",
    "#                    (frame, (left top corner), (bottom right corner), rectangle color, thickness)\n",
    "        cv2.putText(frame, name, (x1,y1-10), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 200), 2)  #Writes name above the rectangle\n",
    "#                  (frame, name of the person in the image, (position of text), font style, (color, thickness))\n",
    "    cv2.imshow('window1', frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()  #make sure to release the video or else you cannot open the video\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b34c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
